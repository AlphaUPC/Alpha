{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d8187aa",
      "metadata": {
        "id": "3d8187aa"
      },
      "source": [
        "# 4. Modelado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0877f3d9",
      "metadata": {
        "id": "0877f3d9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential, save_model, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from collections import Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3a2bea62",
      "metadata": {
        "id": "3a2bea62"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data_final.csv\", sep=\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b80187",
      "metadata": {
        "id": "a5b80187"
      },
      "source": [
        "Como se ha explicado anteriormente, entrenaremos los modelos diferenciando las criptomonedas a evaluar"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced3c7c6",
      "metadata": {
        "id": "ced3c7c6"
      },
      "source": [
        "## 4.2. Ethereum (Paso por paso)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e717b158",
      "metadata": {
        "id": "e717b158"
      },
      "source": [
        "### 4.2.1. Selección del conjunto base para modelado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3ae7c49a",
      "metadata": {
        "id": "3ae7c49a"
      },
      "outputs": [],
      "source": [
        "df_eth = df[df[\"token\"] == \"Ethereum\"].copy()\n",
        "df_eth[\"close\"] = pd.to_numeric(df_eth[\"close\"], errors='coerce')\n",
        "df_eth[\"volume\"] = pd.to_numeric(df_eth[\"volume\"], errors='coerce')\n",
        "df_eth[\"marketCap\"] = pd.to_numeric(df_eth[\"marketCap\"], errors='coerce')\n",
        "df_eth[\"timestamp\"] = pd.to_datetime(df_eth[\"timestamp\"], errors='coerce')\n",
        "df_eth = df_eth.sort_values(\"timestamp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88630299",
      "metadata": {
        "id": "88630299"
      },
      "source": [
        "### 4.2.2. Selección de variables predictoras y target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0debc10c",
      "metadata": {
        "id": "0debc10c"
      },
      "outputs": [],
      "source": [
        "# Selección de variables para Ethereum\n",
        "X_eth = df_eth[[\"close\", \"volume\", \"marketCap\"]].shift(1)\n",
        "y_eth = df_eth[\"close\"]\n",
        "\n",
        "# Eliminando filas con NaN\n",
        "X_eth = X_eth.iloc[1:]\n",
        "y_eth = y_eth.iloc[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c5d1ff",
      "metadata": {
        "id": "f1c5d1ff"
      },
      "source": [
        "### 4.2.3. División del conjunto en entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "83775f49",
      "metadata": {
        "id": "83775f49"
      },
      "outputs": [],
      "source": [
        "X_train_eth, X_test_eth, y_train_eth, y_test_eth = train_test_split(X_eth, y_eth, shuffle=False, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b8d898b",
      "metadata": {
        "id": "7b8d898b"
      },
      "source": [
        "### 4.2.4. Escalamiento de variables numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "accd9c91",
      "metadata": {
        "id": "accd9c91"
      },
      "outputs": [],
      "source": [
        "scaler_eth = StandardScaler()\n",
        "X_train_eth_scaled = scaler_eth.fit_transform(X_train_eth)\n",
        "X_test_eth_scaled = scaler_eth.transform(X_test_eth)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaf6b94c",
      "metadata": {
        "id": "aaf6b94c"
      },
      "source": [
        "### 4.2.5. Aplicando Regresión Lineal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4fe8de6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fe8de6e",
        "outputId": "2e38db6c-7802-4ab8-a809-c6b0e42d2642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Lineal Base - Ethereum:\n",
            "{'MAE': 74.31143445494561, 'MSE': 10908.545793630792, 'RMSE': np.float64(104.44398399922703), 'R^2': 0.9575978579606493}\n"
          ]
        }
      ],
      "source": [
        "# Regresión Lineal Base para Ethereum\n",
        "lr_model_eth = LinearRegression()\n",
        "lr_model_eth.fit(X_train_eth_scaled, y_train_eth)\n",
        "y_pred_lr_eth = lr_model_eth.predict(X_test_eth_scaled)\n",
        "\n",
        "# Métricas\n",
        "mae_lr_eth = mean_absolute_error(y_test_eth, y_pred_lr_eth)\n",
        "mse_lr_eth = mean_squared_error(y_test_eth, y_pred_lr_eth)\n",
        "rmse_lr_eth = np.sqrt(mse_lr_eth)\n",
        "r2_lr_eth = r2_score(y_test_eth, y_pred_lr_eth)\n",
        "\n",
        "metricas_lr_eth = {\n",
        "    \"MAE\": mae_lr_eth,\n",
        "    \"MSE\": mse_lr_eth,\n",
        "    \"RMSE\": rmse_lr_eth,\n",
        "    \"R^2\": r2_lr_eth\n",
        "}\n",
        "print(\"Regresión Lineal Base - Ethereum:\")\n",
        "print(metricas_lr_eth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fb57b79c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb57b79c",
        "outputId": "4f73ff62-5cef-4e65-8131-7272e1a89deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Lineal CV - Ethereum:\n",
            "{'MAE': 74.31143445494561, 'RMSE': np.float64(104.44398399922703), 'R^2': 0.9575978579606493}\n"
          ]
        }
      ],
      "source": [
        "# Regresión Lineal con Validación Cruzada - Ethereum\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "lr_cv_eth = LinearRegression()\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "cv_scores_eth = []\n",
        "\n",
        "for train_idx, val_idx in tscv.split(X_train_eth_scaled):\n",
        "    X_train_cv, X_val_cv = X_train_eth_scaled[train_idx], X_train_eth_scaled[val_idx]\n",
        "    y_train_cv, y_val_cv = y_train_eth.iloc[train_idx], y_train_eth.iloc[val_idx]\n",
        "\n",
        "    lr_cv_eth.fit(X_train_cv, y_train_cv)\n",
        "    y_pred_cv = lr_cv_eth.predict(X_val_cv)\n",
        "    cv_scores_eth.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
        "\n",
        "lr_cv_eth.fit(X_train_eth_scaled, y_train_eth)\n",
        "y_pred_lr_cv_eth = lr_cv_eth.predict(X_test_eth_scaled)\n",
        "\n",
        "mae_lr_cv_eth = mean_absolute_error(y_test_eth, y_pred_lr_cv_eth)\n",
        "rmse_lr_cv_eth = np.sqrt(mean_squared_error(y_test_eth, y_pred_lr_cv_eth))\n",
        "r2_lr_cv_eth = r2_score(y_test_eth, y_pred_lr_cv_eth)\n",
        "\n",
        "metricas_lr_cv_eth = {\n",
        "    \"MAE\": mae_lr_cv_eth,\n",
        "    \"RMSE\": rmse_lr_cv_eth,\n",
        "    \"R^2\": r2_lr_cv_eth\n",
        "}\n",
        "print(\"Regresión Lineal CV - Ethereum:\")\n",
        "print(metricas_lr_cv_eth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "efff00d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efff00d4",
        "outputId": "954be290-ec02-4ae5-e270-a57bd692fe1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación Regresión Lineal - Ethereum:\n",
            "Base - MAE: 74.31, RMSE: 104.44, R²: 0.9576\n",
            "CV - MAE: 74.31, RMSE: 104.44, R²: 0.9576\n",
            "Ridge - MAE: 73.97, RMSE: 103.87, R²: 0.9581\n",
            "Lasso - MAE: 73.76, RMSE: 103.68, R²: 0.9582\n"
          ]
        }
      ],
      "source": [
        "# Ridge y Lasso para Ethereum\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "# Ridge\n",
        "ridge_eth = Ridge(alpha=1.0)\n",
        "ridge_eth.fit(X_train_eth_scaled, y_train_eth)\n",
        "y_pred_ridge_eth = ridge_eth.predict(X_test_eth_scaled)\n",
        "\n",
        "mae_ridge_eth = mean_absolute_error(y_test_eth, y_pred_ridge_eth)\n",
        "rmse_ridge_eth = np.sqrt(mean_squared_error(y_test_eth, y_pred_ridge_eth))\n",
        "r2_ridge_eth = r2_score(y_test_eth, y_pred_ridge_eth)\n",
        "\n",
        "# Lasso\n",
        "lasso_eth = Lasso(alpha=0.1)\n",
        "lasso_eth.fit(X_train_eth_scaled, y_train_eth)\n",
        "y_pred_lasso_eth = lasso_eth.predict(X_test_eth_scaled)\n",
        "\n",
        "mae_lasso_eth = mean_absolute_error(y_test_eth, y_pred_lasso_eth)\n",
        "rmse_lasso_eth = np.sqrt(mean_squared_error(y_test_eth, y_pred_lasso_eth))\n",
        "r2_lasso_eth = r2_score(y_test_eth, y_pred_lasso_eth)\n",
        "\n",
        "# Comparación de resultados de Regresión Lineal\n",
        "print(\"Comparación Regresión Lineal - Ethereum:\")\n",
        "print(f\"Base - MAE: {mae_lr_eth:.2f}, RMSE: {rmse_lr_eth:.2f}, R²: {r2_lr_eth:.4f}\")\n",
        "print(f\"CV - MAE: {mae_lr_cv_eth:.2f}, RMSE: {rmse_lr_cv_eth:.2f}, R²: {r2_lr_cv_eth:.4f}\")\n",
        "print(f\"Ridge - MAE: {mae_ridge_eth:.2f}, RMSE: {rmse_ridge_eth:.2f}, R²: {r2_ridge_eth:.4f}\")\n",
        "print(f\"Lasso - MAE: {mae_lasso_eth:.2f}, RMSE: {rmse_lasso_eth:.2f}, R²: {r2_lasso_eth:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f01598fe",
      "metadata": {
        "id": "f01598fe"
      },
      "source": [
        "### 4.2.6. Aplicando Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5ac37794",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ac37794",
        "outputId": "5aafccd2-da20-4336-d28d-3cf4e8e75510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación Random Forest - Ethereum:\n",
            "Base - MAE: 106.42, RMSE: 142.92, R²: 0.9206\n",
            "CV - MAE: 106.42, RMSE: 142.92, R²: 0.9206\n",
            "Optimizado - MAE: 99.64, RMSE: 134.70, R²: 0.9295\n"
          ]
        }
      ],
      "source": [
        "# Random Forest para Ethereum\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Random Forest Base\n",
        "rf_base_eth = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_base_eth.fit(X_train_eth, y_train_eth)\n",
        "y_pred_rf_base_eth = rf_base_eth.predict(X_test_eth)\n",
        "\n",
        "mae_rf_base_eth = mean_absolute_error(y_test_eth, y_pred_rf_base_eth)\n",
        "rmse_rf_base_eth = np.sqrt(mean_squared_error(y_test_eth, y_pred_rf_base_eth))\n",
        "r2_rf_base_eth = r2_score(y_test_eth, y_pred_rf_base_eth)\n",
        "\n",
        "# Random Forest con CV\n",
        "rf_cv_eth = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_cv_scores_eth = []\n",
        "\n",
        "for train_idx, val_idx in tscv.split(X_train_eth):\n",
        "    X_train_rf_cv, X_val_rf_cv = X_train_eth.iloc[train_idx], X_train_eth.iloc[val_idx]\n",
        "    y_train_rf_cv, y_val_rf_cv = y_train_eth.iloc[train_idx], y_train_eth.iloc[val_idx]\n",
        "\n",
        "    rf_cv_eth.fit(X_train_rf_cv, y_train_rf_cv)\n",
        "    y_pred_rf_cv = rf_cv_eth.predict(X_val_rf_cv)\n",
        "    rf_cv_scores_eth.append(mean_absolute_error(y_val_rf_cv, y_pred_rf_cv))\n",
        "\n",
        "rf_cv_eth.fit(X_train_eth, y_train_eth)\n",
        "y_pred_rf_cv_eth = rf_cv_eth.predict(X_test_eth)\n",
        "\n",
        "mae_rf_cv_eth = mean_absolute_error(y_test_eth, y_pred_rf_cv_eth)\n",
        "rmse_rf_cv_eth = np.sqrt(mean_squared_error(y_test_eth, y_pred_rf_cv_eth))\n",
        "r2_rf_cv_eth = r2_score(y_test_eth, y_pred_rf_cv_eth)\n",
        "\n",
        "# Random Forest Optimizado\n",
        "param_dist_eth = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "rf_opt_eth = RandomForestRegressor(random_state=42)\n",
        "random_search_eth = RandomizedSearchCV(\n",
        "    estimator=rf_opt_eth,\n",
        "    param_distributions=param_dist_eth,\n",
        "    n_iter=25,\n",
        "    cv=TimeSeriesSplit(n_splits=5),\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    random_state=42,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "random_search_eth.fit(X_train_eth, y_train_eth)\n",
        "rf_optimized_eth = random_search_eth.best_estimator_\n",
        "y_pred_rf_opt_eth = rf_optimized_eth.predict(X_test_eth)\n",
        "\n",
        "mae_rf_opt_eth = mean_absolute_error(y_test_eth, y_pred_rf_opt_eth)\n",
        "rmse_rf_opt_eth = np.sqrt(mean_squared_error(y_test_eth, y_pred_rf_opt_eth))\n",
        "r2_rf_opt_eth = r2_score(y_test_eth, y_pred_rf_opt_eth)\n",
        "\n",
        "# Comparación Random Forest\n",
        "print(\"Comparación Random Forest - Ethereum:\")\n",
        "print(f\"Base - MAE: {mae_rf_base_eth:.2f}, RMSE: {rmse_rf_base_eth:.2f}, R²: {r2_rf_base_eth:.4f}\")\n",
        "print(f\"CV - MAE: {mae_rf_cv_eth:.2f}, RMSE: {rmse_rf_cv_eth:.2f}, R²: {r2_rf_cv_eth:.4f}\")\n",
        "print(f\"Optimizado - MAE: {mae_rf_opt_eth:.2f}, RMSE: {rmse_rf_opt_eth:.2f}, R²: {r2_rf_opt_eth:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "650ba36e",
      "metadata": {
        "id": "650ba36e"
      },
      "source": [
        "### 4.2.7. Aplicando LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "346e2d64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "346e2d64",
        "outputId": "2e6a1561-e159-4163-e4f9-a070114f3bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación LSTM - Ethereum:\n",
            "Base - MAE: 551.16, RMSE: 708.38, R²: -1.0003\n",
            "Opt1 - MAE: 2940.15, RMSE: 2982.51, R²: -34.4581\n",
            "Opt2 - MAE: 2943.96, RMSE: 2986.27, R²: -34.5475\n",
            "Opt3 - MAE: 2948.85, RMSE: 2990.92, R²: -34.7994\n"
          ]
        }
      ],
      "source": [
        "# LSTM para Ethereum\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Preparación de datos para LSTM\n",
        "X_full_eth = df_eth[[\"close\", \"volume\", \"marketCap\"]].values\n",
        "y_full_eth = df_eth[\"close\"].values\n",
        "\n",
        "scaler_lstm_eth = StandardScaler()\n",
        "X_scaled_eth = scaler_lstm_eth.fit_transform(X_full_eth)\n",
        "\n",
        "lookback = 30\n",
        "X_seq_eth = []\n",
        "y_seq_eth = []\n",
        "\n",
        "for i in range(lookback, len(X_scaled_eth)):\n",
        "    X_seq_eth.append(X_scaled_eth[i - lookback:i])\n",
        "    y_seq_eth.append(y_full_eth[i])\n",
        "\n",
        "X_seq_eth = np.array(X_seq_eth)\n",
        "y_seq_eth = np.array(y_seq_eth)\n",
        "\n",
        "split_eth = int(len(X_seq_eth) * 0.8)\n",
        "X_train_lstm_eth, X_test_lstm_eth = X_seq_eth[:split_eth], X_seq_eth[split_eth:]\n",
        "y_train_lstm_eth, y_test_lstm_eth = y_seq_eth[:split_eth], y_seq_eth[split_eth:]\n",
        "\n",
        "# Modelo LSTM Base\n",
        "model_lstm_base_eth = Sequential()\n",
        "model_lstm_base_eth.add(LSTM(50, activation='relu', input_shape=(lookback, 3)))\n",
        "model_lstm_base_eth.add(Dense(1))\n",
        "model_lstm_base_eth.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "model_lstm_base_eth.fit(X_train_lstm_eth, y_train_lstm_eth, epochs=50, batch_size=32, verbose=0)\n",
        "y_pred_lstm_base_eth = model_lstm_base_eth.predict(X_test_lstm_eth, verbose=0)\n",
        "\n",
        "mae_lstm_base_eth = mean_absolute_error(y_test_lstm_eth, y_pred_lstm_base_eth)\n",
        "rmse_lstm_base_eth = np.sqrt(mean_squared_error(y_test_lstm_eth, y_pred_lstm_base_eth))\n",
        "r2_lstm_base_eth = r2_score(y_test_lstm_eth, y_pred_lstm_base_eth)\n",
        "\n",
        "# Modelo LSTM Optimización 1 (más capas)\n",
        "model_lstm_opt1_eth = Sequential()\n",
        "model_lstm_opt1_eth.add(LSTM(50, return_sequences=True, input_shape=(lookback, 3)))\n",
        "model_lstm_opt1_eth.add(LSTM(50))\n",
        "model_lstm_opt1_eth.add(Dense(1))\n",
        "model_lstm_opt1_eth.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "model_lstm_opt1_eth.fit(X_train_lstm_eth, y_train_lstm_eth, epochs=50, batch_size=32, verbose=0)\n",
        "y_pred_lstm_opt1_eth = model_lstm_opt1_eth.predict(X_test_lstm_eth, verbose=0)\n",
        "\n",
        "mae_lstm_opt1_eth = mean_absolute_error(y_test_lstm_eth, y_pred_lstm_opt1_eth)\n",
        "rmse_lstm_opt1_eth = np.sqrt(mean_squared_error(y_test_lstm_eth, y_pred_lstm_opt1_eth))\n",
        "r2_lstm_opt1_eth = r2_score(y_test_lstm_eth, y_pred_lstm_opt1_eth)\n",
        "\n",
        "# Modelo LSTM Optimización 2 (con Dropout)\n",
        "model_lstm_opt2_eth = Sequential()\n",
        "model_lstm_opt2_eth.add(LSTM(100, return_sequences=True, input_shape=(lookback, 3)))\n",
        "model_lstm_opt2_eth.add(Dropout(0.2))\n",
        "model_lstm_opt2_eth.add(LSTM(50))\n",
        "model_lstm_opt2_eth.add(Dropout(0.2))\n",
        "model_lstm_opt2_eth.add(Dense(1))\n",
        "model_lstm_opt2_eth.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "model_lstm_opt2_eth.fit(X_train_lstm_eth, y_train_lstm_eth, epochs=50, batch_size=32, verbose=0)\n",
        "y_pred_lstm_opt2_eth = model_lstm_opt2_eth.predict(X_test_lstm_eth, verbose=0)\n",
        "\n",
        "mae_lstm_opt2_eth = mean_absolute_error(y_test_lstm_eth, y_pred_lstm_opt2_eth)\n",
        "rmse_lstm_opt2_eth = np.sqrt(mean_squared_error(y_test_lstm_eth, y_pred_lstm_opt2_eth))\n",
        "r2_lstm_opt2_eth = r2_score(y_test_lstm_eth, y_pred_lstm_opt2_eth)\n",
        "\n",
        "# Modelo LSTM Optimización 3 (lookback 60)\n",
        "lookback_60 = 60\n",
        "X_seq_eth_60 = []\n",
        "y_seq_eth_60 = []\n",
        "\n",
        "for i in range(lookback_60, len(X_scaled_eth)):\n",
        "    X_seq_eth_60.append(X_scaled_eth[i - lookback_60:i])\n",
        "    y_seq_eth_60.append(y_full_eth[i])\n",
        "\n",
        "X_seq_eth_60 = np.array(X_seq_eth_60)\n",
        "y_seq_eth_60 = np.array(y_seq_eth_60)\n",
        "\n",
        "split_eth_60 = int(len(X_seq_eth_60) * 0.8)\n",
        "X_train_lstm_eth_60, X_test_lstm_eth_60 = X_seq_eth_60[:split_eth_60], X_seq_eth_60[split_eth_60:]\n",
        "y_train_lstm_eth_60, y_test_lstm_eth_60 = y_seq_eth_60[:split_eth_60], y_seq_eth_60[split_eth_60:]\n",
        "\n",
        "model_lstm_opt3_eth = Sequential()\n",
        "model_lstm_opt3_eth.add(LSTM(100, return_sequences=True, input_shape=(lookback_60, 3)))\n",
        "model_lstm_opt3_eth.add(Dropout(0.2))\n",
        "model_lstm_opt3_eth.add(LSTM(50))\n",
        "model_lstm_opt3_eth.add(Dropout(0.2))\n",
        "model_lstm_opt3_eth.add(Dense(1))\n",
        "model_lstm_opt3_eth.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "model_lstm_opt3_eth.fit(X_train_lstm_eth_60, y_train_lstm_eth_60, epochs=50, batch_size=32, verbose=0)\n",
        "y_pred_lstm_opt3_eth = model_lstm_opt3_eth.predict(X_test_lstm_eth_60, verbose=0)\n",
        "\n",
        "mae_lstm_opt3_eth = mean_absolute_error(y_test_lstm_eth_60, y_pred_lstm_opt3_eth)\n",
        "rmse_lstm_opt3_eth = np.sqrt(mean_squared_error(y_test_lstm_eth_60, y_pred_lstm_opt3_eth))\n",
        "r2_lstm_opt3_eth = r2_score(y_test_lstm_eth_60, y_pred_lstm_opt3_eth)\n",
        "\n",
        "# Comparación LSTM\n",
        "print(\"Comparación LSTM - Ethereum:\")\n",
        "print(f\"Base - MAE: {mae_lstm_base_eth:.2f}, RMSE: {rmse_lstm_base_eth:.2f}, R²: {r2_lstm_base_eth:.4f}\")\n",
        "print(f\"Opt1 - MAE: {mae_lstm_opt1_eth:.2f}, RMSE: {rmse_lstm_opt1_eth:.2f}, R²: {r2_lstm_opt1_eth:.4f}\")\n",
        "print(f\"Opt2 - MAE: {mae_lstm_opt2_eth:.2f}, RMSE: {rmse_lstm_opt2_eth:.2f}, R²: {r2_lstm_opt2_eth:.4f}\")\n",
        "print(f\"Opt3 - MAE: {mae_lstm_opt3_eth:.2f}, RMSE: {rmse_lstm_opt3_eth:.2f}, R²: {r2_lstm_opt3_eth:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(lasso_eth, \"modelo_ethereum_lasso.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxN7JHDzJd0I",
        "outputId": "4e763b4a-42e1-4118-8fd1-7776ba83c8ad"
      },
      "id": "OxN7JHDzJd0I",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['modelo_ethereum_lasso.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde2011a",
      "metadata": {
        "id": "fde2011a"
      },
      "source": [
        "## Selección del conjunto base para modelado automatizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "778653f4",
      "metadata": {
        "id": "778653f4"
      },
      "outputs": [],
      "source": [
        "# Función para modelar cualquier criptomoneda\n",
        "def modelo_completo_crypto(df, token_name, print_results=True):\n",
        "    \"\"\"\n",
        "    Aplica todo el pipeline de modelado a una criptomoneda específica\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # 1. Selección del conjunto base\n",
        "    df_token = df[df[\"token\"] == token_name].copy()\n",
        "    df_token[\"close\"] = pd.to_numeric(df_token[\"close\"], errors='coerce')\n",
        "    df_token[\"volume\"] = pd.to_numeric(df_token[\"volume\"], errors='coerce')\n",
        "    df_token[\"marketCap\"] = pd.to_numeric(df_token[\"marketCap\"], errors='coerce')\n",
        "    df_token[\"timestamp\"] = pd.to_datetime(df_token[\"timestamp\"], errors='coerce')\n",
        "    df_token = df_token.sort_values(\"timestamp\")\n",
        "\n",
        "    # 2. Variables predictoras y target\n",
        "    X = df_token[[\"close\", \"volume\", \"marketCap\"]].shift(1)\n",
        "    y = df_token[\"close\"]\n",
        "    X = X.iloc[1:]\n",
        "    y = y.iloc[1:]\n",
        "\n",
        "    # 3. División del conjunto\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
        "\n",
        "    # 4. Escalamiento\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # 5. REGRESIÓN LINEAL\n",
        "    # Base\n",
        "    lr_model = LinearRegression()\n",
        "    lr_model.fit(X_train_scaled, y_train)\n",
        "    y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "\n",
        "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "    rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
        "    r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "    # CV\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    lr_cv = LinearRegression()\n",
        "    cv_scores = []\n",
        "\n",
        "    for train_idx, val_idx in tscv.split(X_train_scaled):\n",
        "        X_train_cv, X_val_cv = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "        y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        lr_cv.fit(X_train_cv, y_train_cv)\n",
        "        y_pred_cv = lr_cv.predict(X_val_cv)\n",
        "        cv_scores.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
        "\n",
        "    lr_cv.fit(X_train_scaled, y_train)\n",
        "    y_pred_lr_cv = lr_cv.predict(X_test_scaled)\n",
        "\n",
        "    mae_lr_cv = mean_absolute_error(y_test, y_pred_lr_cv)\n",
        "    rmse_lr_cv = np.sqrt(mean_squared_error(y_test, y_pred_lr_cv))\n",
        "    r2_lr_cv = r2_score(y_test, y_pred_lr_cv)\n",
        "\n",
        "    # Ridge\n",
        "    ridge = Ridge(alpha=1.0)\n",
        "    ridge.fit(X_train_scaled, y_train)\n",
        "    y_pred_ridge = ridge.predict(X_test_scaled)\n",
        "\n",
        "    mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "    rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "    r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "    # Lasso\n",
        "    lasso = Lasso(alpha=0.1)\n",
        "    lasso.fit(X_train_scaled, y_train)\n",
        "    y_pred_lasso = lasso.predict(X_test_scaled)\n",
        "\n",
        "    mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "    rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
        "    r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "\n",
        "    # 6. RANDOM FOREST\n",
        "    # Base\n",
        "    rf_base = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_base.fit(X_train, y_train)\n",
        "    y_pred_rf_base = rf_base.predict(X_test)\n",
        "\n",
        "    mae_rf_base = mean_absolute_error(y_test, y_pred_rf_base)\n",
        "    rmse_rf_base = np.sqrt(mean_squared_error(y_test, y_pred_rf_base))\n",
        "    r2_rf_base = r2_score(y_test, y_pred_rf_base)\n",
        "\n",
        "    # CV\n",
        "    rf_cv = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_cv_scores = []\n",
        "\n",
        "    for train_idx, val_idx in tscv.split(X_train):\n",
        "        X_train_rf_cv, X_val_rf_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_train_rf_cv, y_val_rf_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        rf_cv.fit(X_train_rf_cv, y_train_rf_cv)\n",
        "        y_pred_rf_cv = rf_cv.predict(X_val_rf_cv)\n",
        "        rf_cv_scores.append(mean_absolute_error(y_val_rf_cv, y_pred_rf_cv))\n",
        "\n",
        "    rf_cv.fit(X_train, y_train)\n",
        "    y_pred_rf_cv = rf_cv.predict(X_test)\n",
        "\n",
        "    mae_rf_cv = mean_absolute_error(y_test, y_pred_rf_cv)\n",
        "    rmse_rf_cv = np.sqrt(mean_squared_error(y_test, y_pred_rf_cv))\n",
        "    r2_rf_cv = r2_score(y_test, y_pred_rf_cv)\n",
        "\n",
        "    # Optimizado\n",
        "    param_dist = {\n",
        "        'n_estimators': [100, 150, 200],\n",
        "        'max_depth': [5, 10, 15, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'max_features': ['sqrt']\n",
        "    }\n",
        "\n",
        "    rf_opt = RandomForestRegressor(random_state=42)\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf_opt,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=25,\n",
        "        cv=TimeSeriesSplit(n_splits=5),\n",
        "        scoring='neg_mean_absolute_error',\n",
        "        random_state=42,\n",
        "        n_jobs=1\n",
        "    )\n",
        "\n",
        "    random_search.fit(X_train, y_train)\n",
        "    rf_optimized = random_search.best_estimator_\n",
        "    y_pred_rf_opt = rf_optimized.predict(X_test)\n",
        "\n",
        "    mae_rf_opt = mean_absolute_error(y_test, y_pred_rf_opt)\n",
        "    rmse_rf_opt = np.sqrt(mean_squared_error(y_test, y_pred_rf_opt))\n",
        "    r2_rf_opt = r2_score(y_test, y_pred_rf_opt)\n",
        "\n",
        "    # 7. LSTM\n",
        "    # Preparación de datos\n",
        "    X_full = df_token[[\"close\", \"volume\", \"marketCap\"]].values\n",
        "    y_full = df_token[\"close\"].values\n",
        "\n",
        "    scaler_lstm = StandardScaler()\n",
        "    X_scaled_lstm = scaler_lstm.fit_transform(X_full)\n",
        "\n",
        "    lookback = 30\n",
        "    X_seq = []\n",
        "    y_seq = []\n",
        "\n",
        "    for i in range(lookback, len(X_scaled_lstm)):\n",
        "        X_seq.append(X_scaled_lstm[i - lookback:i])\n",
        "        y_seq.append(y_full[i])\n",
        "\n",
        "    X_seq = np.array(X_seq)\n",
        "    y_seq = np.array(y_seq)\n",
        "\n",
        "    split = int(len(X_seq) * 0.8)\n",
        "    X_train_lstm, X_test_lstm = X_seq[:split], X_seq[split:]\n",
        "    y_train_lstm, y_test_lstm = y_seq[:split], y_seq[split:]\n",
        "\n",
        "    # Base LSTM\n",
        "    model_lstm_base = Sequential()\n",
        "    model_lstm_base.add(LSTM(50, activation='relu', input_shape=(lookback, 3)))\n",
        "    model_lstm_base.add(Dense(1))\n",
        "    model_lstm_base.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "    model_lstm_base.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, verbose=0)\n",
        "    y_pred_lstm_base = model_lstm_base.predict(X_test_lstm, verbose=0)\n",
        "\n",
        "    mae_lstm_base = mean_absolute_error(y_test_lstm, y_pred_lstm_base)\n",
        "    rmse_lstm_base = np.sqrt(mean_squared_error(y_test_lstm, y_pred_lstm_base))\n",
        "    r2_lstm_base = r2_score(y_test_lstm, y_pred_lstm_base)\n",
        "\n",
        "    # LSTM Opt1 (más capas)\n",
        "    model_lstm_opt1 = Sequential()\n",
        "    model_lstm_opt1.add(LSTM(50, return_sequences=True, input_shape=(lookback, 3)))\n",
        "    model_lstm_opt1.add(LSTM(50))\n",
        "    model_lstm_opt1.add(Dense(1))\n",
        "    model_lstm_opt1.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "    model_lstm_opt1.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, verbose=0)\n",
        "    y_pred_lstm_opt1 = model_lstm_opt1.predict(X_test_lstm, verbose=0)\n",
        "\n",
        "    mae_lstm_opt1 = mean_absolute_error(y_test_lstm, y_pred_lstm_opt1)\n",
        "    rmse_lstm_opt1 = np.sqrt(mean_squared_error(y_test_lstm, y_pred_lstm_opt1))\n",
        "    r2_lstm_opt1 = r2_score(y_test_lstm, y_pred_lstm_opt1)\n",
        "\n",
        "    # LSTM Opt2 (con Dropout)\n",
        "    model_lstm_opt2 = Sequential()\n",
        "    model_lstm_opt2.add(LSTM(100, return_sequences=True, input_shape=(lookback, 3)))\n",
        "    model_lstm_opt2.add(Dropout(0.2))\n",
        "    model_lstm_opt2.add(LSTM(50))\n",
        "    model_lstm_opt2.add(Dropout(0.2))\n",
        "    model_lstm_opt2.add(Dense(1))\n",
        "    model_lstm_opt2.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "    model_lstm_opt2.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, verbose=0)\n",
        "    y_pred_lstm_opt2 = model_lstm_opt2.predict(X_test_lstm, verbose=0)\n",
        "\n",
        "    mae_lstm_opt2 = mean_absolute_error(y_test_lstm, y_pred_lstm_opt2)\n",
        "    rmse_lstm_opt2 = np.sqrt(mean_squared_error(y_test_lstm, y_pred_lstm_opt2))\n",
        "    r2_lstm_opt2 = r2_score(y_test_lstm, y_pred_lstm_opt2)\n",
        "\n",
        "    # LSTM Opt3 (lookback 60)\n",
        "    lookback_60 = 60\n",
        "    X_seq_60 = []\n",
        "    y_seq_60 = []\n",
        "\n",
        "    for i in range(lookback_60, len(X_scaled_lstm)):\n",
        "        X_seq_60.append(X_scaled_lstm[i - lookback_60:i])\n",
        "        y_seq_60.append(y_full[i])\n",
        "\n",
        "    X_seq_60 = np.array(X_seq_60)\n",
        "    y_seq_60 = np.array(y_seq_60)\n",
        "\n",
        "    split_60 = int(len(X_seq_60) * 0.8)\n",
        "    X_train_lstm_60, X_test_lstm_60 = X_seq_60[:split_60], X_seq_60[split_60:]\n",
        "    y_train_lstm_60, y_test_lstm_60 = y_seq_60[:split_60], y_seq_60[split_60:]\n",
        "\n",
        "    model_lstm_opt3 = Sequential()\n",
        "    model_lstm_opt3.add(LSTM(100, return_sequences=True, input_shape=(lookback_60, 3)))\n",
        "    model_lstm_opt3.add(Dropout(0.2))\n",
        "    model_lstm_opt3.add(LSTM(50))\n",
        "    model_lstm_opt3.add(Dropout(0.2))\n",
        "    model_lstm_opt3.add(Dense(1))\n",
        "    model_lstm_opt3.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "    model_lstm_opt3.fit(X_train_lstm_60, y_train_lstm_60, epochs=50, batch_size=32, verbose=0)\n",
        "    y_pred_lstm_opt3 = model_lstm_opt3.predict(X_test_lstm_60, verbose=0)\n",
        "\n",
        "    mae_lstm_opt3 = mean_absolute_error(y_test_lstm_60, y_pred_lstm_opt3)\n",
        "    rmse_lstm_opt3 = np.sqrt(mean_squared_error(y_test_lstm_60, y_pred_lstm_opt3))\n",
        "    r2_lstm_opt3 = r2_score(y_test_lstm_60, y_pred_lstm_opt3)\n",
        "\n",
        "    # 8. Compilar resultados\n",
        "    results = {\n",
        "        'token': token_name,\n",
        "        'regresion_lineal': {\n",
        "            'base': {'MAE': mae_lr, 'RMSE': rmse_lr, 'R2': r2_lr},\n",
        "            'cv': {'MAE': mae_lr_cv, 'RMSE': rmse_lr_cv, 'R2': r2_lr_cv},\n",
        "            'ridge': {'MAE': mae_ridge, 'RMSE': rmse_ridge, 'R2': r2_ridge},\n",
        "            'lasso': {'MAE': mae_lasso, 'RMSE': rmse_lasso, 'R2': r2_lasso}\n",
        "        },\n",
        "        'random_forest': {\n",
        "            'base': {'MAE': mae_rf_base, 'RMSE': rmse_rf_base, 'R2': r2_rf_base},\n",
        "            'cv': {'MAE': mae_rf_cv, 'RMSE': rmse_rf_cv, 'R2': r2_rf_cv},\n",
        "            'optimizado': {'MAE': mae_rf_opt, 'RMSE': rmse_rf_opt, 'R2': r2_rf_opt}\n",
        "        },\n",
        "        'lstm': {\n",
        "            'base': {'MAE': mae_lstm_base, 'RMSE': rmse_lstm_base, 'R2': r2_lstm_base},\n",
        "            'opt1': {'MAE': mae_lstm_opt1, 'RMSE': rmse_lstm_opt1, 'R2': r2_lstm_opt1},\n",
        "            'opt2': {'MAE': mae_lstm_opt2, 'RMSE': rmse_lstm_opt2, 'R2': r2_lstm_opt2},\n",
        "            'opt3': {'MAE': mae_lstm_opt3, 'RMSE': rmse_lstm_opt3, 'R2': r2_lstm_opt3}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if print_results:\n",
        "        print(f\"\\\\n{'='*50}\")\n",
        "        print(f\"RESULTADOS PARA {token_name.upper()}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        print(f\"\\\\nREGRESIÓN LINEAL:\")\n",
        "        print(f\"Base - MAE: {mae_lr:.2f}, RMSE: {rmse_lr:.2f}, R²: {r2_lr:.4f}\")\n",
        "        print(f\"CV - MAE: {mae_lr_cv:.2f}, RMSE: {rmse_lr_cv:.2f}, R²: {r2_lr_cv:.4f}\")\n",
        "        print(f\"Ridge - MAE: {mae_ridge:.2f}, RMSE: {rmse_ridge:.2f}, R²: {r2_ridge:.4f}\")\n",
        "        print(f\"Lasso - MAE: {mae_lasso:.2f}, RMSE: {rmse_lasso:.2f}, R²: {r2_lasso:.4f}\")\n",
        "\n",
        "        print(f\"\\\\nRANDOM FOREST:\")\n",
        "        print(f\"Base - MAE: {mae_rf_base:.2f}, RMSE: {rmse_rf_base:.2f}, R²: {r2_rf_base:.4f}\")\n",
        "        print(f\"CV - MAE: {mae_rf_cv:.2f}, RMSE: {rmse_rf_cv:.2f}, R²: {r2_rf_cv:.4f}\")\n",
        "        print(f\"Optimizado - MAE: {mae_rf_opt:.2f}, RMSE: {rmse_rf_opt:.2f}, R²: {r2_rf_opt:.4f}\")\n",
        "\n",
        "        print(f\"\\\\nLSTM:\")\n",
        "        print(f\"Base - MAE: {mae_lstm_base:.2f}, RMSE: {rmse_lstm_base:.2f}, R²: {r2_lstm_base:.4f}\")\n",
        "        print(f\"Opt1 - MAE: {mae_lstm_opt1:.2f}, RMSE: {rmse_lstm_opt1:.2f}, R²: {r2_lstm_opt1:.4f}\")\n",
        "        print(f\"Opt2 - MAE: {mae_lstm_opt2:.2f}, RMSE: {rmse_lstm_opt2:.2f}, R²: {r2_lstm_opt2:.4f}\")\n",
        "        print(f\"Opt3 - MAE: {mae_lstm_opt3:.2f}, RMSE: {rmse_lstm_opt3:.2f}, R²: {r2_lstm_opt3:.4f}\")\n",
        "\n",
        "    modelos_mae = {\n",
        "        'lr_base'      : (lr_model,        mae_lr),\n",
        "        'lr_cv'        : (lr_cv,           mae_lr_cv),\n",
        "        'ridge'        : (ridge,           mae_ridge),\n",
        "        'lasso'        : (lasso,           mae_lasso),\n",
        "        'rf_base'      : (rf_base,         mae_rf_base),\n",
        "        'rf_cv'        : (rf_cv,           mae_rf_cv),\n",
        "        'rf_opt'       : (rf_optimized,    mae_rf_opt),\n",
        "        'lstm_base'    : (model_lstm_base, mae_lstm_base),\n",
        "        'lstm_opt1'    : (model_lstm_opt1, mae_lstm_opt1),\n",
        "        'lstm_opt2'    : (model_lstm_opt2, mae_lstm_opt2),\n",
        "        'lstm_opt3'    : (model_lstm_opt3, mae_lstm_opt3),\n",
        "    }\n",
        "\n",
        "    # 9. Seleccionar el nombre con el MAE mínimo\n",
        "    best_name, (best_model, best_mae) = min(modelos_mae.items(), key=lambda kv: kv[1][1])\n",
        "\n",
        "    if print_results:\n",
        "        print(f\"\\n>> El mejor modelo es '{best_name}' con MAE = {best_mae:.4f}\")\n",
        "\n",
        "    # 10. Guardar el modelo\n",
        "    filename = f\"{token_name}_{best_name}.h5\"\n",
        "    # Si es un modelo Keras (hereda de tf.keras.Model), usa save()\n",
        "    from tensorflow.keras import Model as KerasModel\n",
        "    if isinstance(best_model, KerasModel):\n",
        "        best_model.save(filename)\n",
        "    else:\n",
        "        joblib.dump(best_model, filename)\n",
        "\n",
        "    if print_results:\n",
        "        print(f\">> Modelo guardado en: {filename}\")\n",
        "\n",
        "    # 11. Devolver el nombre y ruta del mejor modelo\n",
        "    results['best_model'] = {'name': best_name, 'mae': best_mae, 'path': filename}\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Ethereum"
      ],
      "metadata": {
        "id": "BYOsK4_jUPoo"
      },
      "id": "BYOsK4_jUPoo"
    },
    {
      "cell_type": "code",
      "source": [
        "results_eth = modelo_completo_crypto(df, \"Ethereum\", print_results=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MHF5nPXTwCF",
        "outputId": "315800ed-de44-4bb8-9189-700406ab9b72"
      },
      "id": "5MHF5nPXTwCF",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n==================================================\n",
            "RESULTADOS PARA ETHEREUM\n",
            "==================================================\n",
            "\\nREGRESIÓN LINEAL:\n",
            "Base - MAE: 74.31, RMSE: 104.44, R²: 0.9576\n",
            "CV - MAE: 74.31, RMSE: 104.44, R²: 0.9576\n",
            "Ridge - MAE: 73.97, RMSE: 103.87, R²: 0.9581\n",
            "Lasso - MAE: 73.76, RMSE: 103.68, R²: 0.9582\n",
            "\\nRANDOM FOREST:\n",
            "Base - MAE: 106.42, RMSE: 142.92, R²: 0.9206\n",
            "CV - MAE: 106.42, RMSE: 142.92, R²: 0.9206\n",
            "Optimizado - MAE: 99.64, RMSE: 134.70, R²: 0.9295\n",
            "\\nLSTM:\n",
            "Base - MAE: 401.59, RMSE: 524.26, R²: -0.0956\n",
            "Opt1 - MAE: 2942.95, RMSE: 2985.27, R²: -34.5237\n",
            "Opt2 - MAE: 2943.00, RMSE: 2985.32, R²: -34.5250\n",
            "Opt3 - MAE: 2949.84, RMSE: 2991.89, R²: -34.8227\n",
            "\n",
            ">> El mejor modelo es 'lasso' con MAE = 73.7587\n",
            ">> Modelo guardado en: Ethereum_lasso.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a96730",
      "metadata": {
        "id": "02a96730"
      },
      "source": [
        "## 4.3. Polkadot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0c0475fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c0475fe",
        "outputId": "af44a8d7-ff3e-4f76-9a8b-d2d4db0c1e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n==================================================\n",
            "RESULTADOS PARA POLKADOT\n",
            "==================================================\n",
            "\\nREGRESIÓN LINEAL:\n",
            "Base - MAE: 0.77, RMSE: 0.92, R²: 0.7724\n",
            "CV - MAE: 0.77, RMSE: 0.92, R²: 0.7724\n",
            "Ridge - MAE: 0.78, RMSE: 0.93, R²: 0.7630\n",
            "Lasso - MAE: 0.82, RMSE: 0.95, R²: 0.7561\n",
            "\\nRANDOM FOREST:\n",
            "Base - MAE: 0.28, RMSE: 0.45, R²: 0.9460\n",
            "CV - MAE: 0.28, RMSE: 0.45, R²: 0.9460\n",
            "Optimizado - MAE: 0.73, RMSE: 1.03, R²: 0.7121\n",
            "\\nLSTM:\n",
            "Base - MAE: 0.84, RMSE: 1.09, R²: 0.6789\n",
            "Opt1 - MAE: 0.70, RMSE: 0.96, R²: 0.7527\n",
            "Opt2 - MAE: 0.88, RMSE: 1.07, R²: 0.6935\n",
            "Opt3 - MAE: 0.89, RMSE: 1.08, R²: 0.6853\n",
            "\n",
            ">> El mejor modelo es 'rf_base' con MAE = 0.2762\n",
            ">> Modelo guardado en: Polkadot_rf_base.h5\n"
          ]
        }
      ],
      "source": [
        "results_polkadot = modelo_completo_crypto(df, \"Polkadot\", print_results=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fea3198",
      "metadata": {
        "id": "7fea3198"
      },
      "source": [
        "## 4.4. Oasis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e79fcde5",
      "metadata": {
        "id": "e79fcde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f2a1b9-450b-4348-a44f-6e68acf91aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n==================================================\n",
            "RESULTADOS PARA OASIS\n",
            "==================================================\n",
            "\\nREGRESIÓN LINEAL:\n",
            "Base - MAE: 0.01, RMSE: 0.01, R²: 0.9343\n",
            "CV - MAE: 0.01, RMSE: 0.01, R²: 0.9343\n",
            "Ridge - MAE: 0.01, RMSE: 0.01, R²: 0.9340\n",
            "Lasso - MAE: 0.03, RMSE: 0.03, R²: -0.2526\n",
            "\\nRANDOM FOREST:\n",
            "Base - MAE: 0.00, RMSE: 0.01, R²: 0.9457\n",
            "CV - MAE: 0.00, RMSE: 0.01, R²: 0.9457\n",
            "Optimizado - MAE: 0.01, RMSE: 0.01, R²: 0.8899\n",
            "\\nLSTM:\n",
            "Base - MAE: 0.01, RMSE: 0.01, R²: 0.8906\n",
            "Opt1 - MAE: 0.00, RMSE: 0.01, R²: 0.9509\n",
            "Opt2 - MAE: 0.00, RMSE: 0.01, R²: 0.9463\n",
            "Opt3 - MAE: 0.00, RMSE: 0.01, R²: 0.9244\n",
            "\n",
            ">> El mejor modelo es 'lstm_opt1' con MAE = 0.0040\n",
            ">> Modelo guardado en: Oasis_lstm_opt1.h5\n"
          ]
        }
      ],
      "source": [
        "results_oasis = modelo_completo_crypto(df, \"Oasis\", print_results=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af51cff",
      "metadata": {
        "id": "4af51cff"
      },
      "source": [
        "## 4.5. Nervos Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "290b74a0",
      "metadata": {
        "id": "290b74a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef926856-53a3-49db-a1f5-2f0f3dc54c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n==================================================\n",
            "RESULTADOS PARA NERVOS NETWORK\n",
            "==================================================\n",
            "\\nREGRESIÓN LINEAL:\n",
            "Base - MAE: 0.00, RMSE: 0.00, R²: 0.9568\n",
            "CV - MAE: 0.00, RMSE: 0.00, R²: 0.9568\n",
            "Ridge - MAE: 0.00, RMSE: 0.00, R²: 0.9565\n",
            "Lasso - MAE: 0.01, RMSE: 0.01, R²: -0.9259\n",
            "\\nRANDOM FOREST:\n",
            "Base - MAE: 0.00, RMSE: 0.00, R²: 0.9306\n",
            "CV - MAE: 0.00, RMSE: 0.00, R²: 0.9306\n",
            "Optimizado - MAE: 0.00, RMSE: 0.00, R²: 0.3759\n",
            "\\nLSTM:\n",
            "Base - MAE: 0.00, RMSE: 0.00, R²: 0.2394\n",
            "Opt1 - MAE: 0.00, RMSE: 0.00, R²: 0.8506\n",
            "Opt2 - MAE: 0.00, RMSE: 0.00, R²: 0.9074\n",
            "Opt3 - MAE: 0.00, RMSE: 0.00, R²: 0.8304\n",
            "\n",
            ">> El mejor modelo es 'lr_base' con MAE = 0.0007\n",
            ">> Modelo guardado en: Nervos Network_lr_base.h5\n"
          ]
        }
      ],
      "source": [
        "results_nervos = modelo_completo_crypto(df, \"Nervos Network\", print_results=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93cb6fa",
      "metadata": {
        "id": "a93cb6fa"
      },
      "source": [
        "## 4.6. Terra Classic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8f2f033e",
      "metadata": {
        "id": "8f2f033e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1042c0f6-af74-48d8-8fe4-d67f82bc88d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n==================================================\n",
            "RESULTADOS PARA TERRA CLASSIC\n",
            "==================================================\n",
            "\\nREGRESIÓN LINEAL:\n",
            "Base - MAE: 0.06, RMSE: 0.07, R²: -5852313.4375\n",
            "CV - MAE: 0.06, RMSE: 0.07, R²: -5852313.4375\n",
            "Ridge - MAE: 0.07, RMSE: 0.07, R²: -6002558.6653\n",
            "Lasso - MAE: 0.13, RMSE: 0.13, R²: -22976706.9583\n",
            "\\nRANDOM FOREST:\n",
            "Base - MAE: 0.00, RMSE: 0.00, R²: 0.9135\n",
            "CV - MAE: 0.00, RMSE: 0.00, R²: 0.9135\n",
            "Optimizado - MAE: 0.01, RMSE: 0.02, R²: -739692.1476\n",
            "\\nLSTM:\n",
            "Base - MAE: 0.00, RMSE: 0.00, R²: -5451.1945\n",
            "Opt1 - MAE: 0.01, RMSE: 0.01, R²: -72812.7162\n",
            "Opt2 - MAE: 0.01, RMSE: 0.01, R²: -87542.7872\n",
            "Opt3 - MAE: 0.01, RMSE: 0.01, R²: -71739.4023\n",
            "\n",
            ">> El mejor modelo es 'rf_base' con MAE = 0.0000\n",
            ">> Modelo guardado en: Terra Classic_rf_base.h5\n"
          ]
        }
      ],
      "source": [
        "results_terra = modelo_completo_crypto(df, \"Terra Classic\", print_results=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74313b5c",
      "metadata": {
        "id": "74313b5c"
      },
      "source": [
        "## 4.7. The Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "85179e0f",
      "metadata": {
        "id": "85179e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce7e99a-b150-4bcb-8ef5-26089ea386c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n==================================================\n",
            "RESULTADOS PARA THE GRAPH\n",
            "==================================================\n",
            "\\nREGRESIÓN LINEAL:\n",
            "Base - MAE: 0.02, RMSE: 0.02, R²: 0.9092\n",
            "CV - MAE: 0.02, RMSE: 0.02, R²: 0.9092\n",
            "Ridge - MAE: 0.02, RMSE: 0.02, R²: 0.9068\n",
            "Lasso - MAE: 0.05, RMSE: 0.05, R²: 0.5158\n",
            "\\nRANDOM FOREST:\n",
            "Base - MAE: 0.02, RMSE: 0.02, R²: 0.9133\n",
            "CV - MAE: 0.02, RMSE: 0.02, R²: 0.9133\n",
            "Optimizado - MAE: 0.04, RMSE: 0.06, R²: 0.4160\n",
            "\\nLSTM:\n",
            "Base - MAE: 0.02, RMSE: 0.03, R²: 0.8350\n",
            "Opt1 - MAE: 0.01, RMSE: 0.01, R²: 0.9611\n",
            "Opt2 - MAE: 0.01, RMSE: 0.02, R²: 0.9450\n",
            "Opt3 - MAE: 0.01, RMSE: 0.02, R²: 0.9293\n",
            "\n",
            ">> El mejor modelo es 'lstm_opt1' con MAE = 0.0105\n",
            ">> Modelo guardado en: The Graph_lstm_opt1.h5\n"
          ]
        }
      ],
      "source": [
        "results_graph = modelo_completo_crypto(df, \"The Graph\", print_results=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "869cb271",
      "metadata": {
        "id": "869cb271"
      },
      "source": [
        "## 4.8. Algorand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4a8ddc3a",
      "metadata": {
        "id": "4a8ddc3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079370fb-f155-4125-e091-b57cd7bcf4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n==================================================\n",
            "RESULTADOS PARA ALGORAND\n",
            "==================================================\n",
            "\\nREGRESIÓN LINEAL:\n",
            "Base - MAE: 0.01, RMSE: 0.02, R²: 0.9534\n",
            "CV - MAE: 0.01, RMSE: 0.02, R²: 0.9534\n",
            "Ridge - MAE: 0.01, RMSE: 0.02, R²: 0.9515\n",
            "Lasso - MAE: 0.08, RMSE: 0.08, R²: 0.0709\n",
            "\\nRANDOM FOREST:\n",
            "Base - MAE: 0.01, RMSE: 0.02, R²: 0.9660\n",
            "CV - MAE: 0.01, RMSE: 0.02, R²: 0.9660\n",
            "Optimizado - MAE: 0.03, RMSE: 0.05, R²: 0.6419\n",
            "\\nLSTM:\n",
            "Base - MAE: 0.01, RMSE: 0.02, R²: 0.9526\n",
            "Opt1 - MAE: 0.01, RMSE: 0.02, R²: 0.9689\n",
            "Opt2 - MAE: 0.01, RMSE: 0.02, R²: 0.9470\n",
            "Opt3 - MAE: 0.01, RMSE: 0.02, R²: 0.9463\n",
            "\n",
            ">> El mejor modelo es 'lstm_opt1' con MAE = 0.0088\n",
            ">> Modelo guardado en: Algorand_lstm_opt1.h5\n"
          ]
        }
      ],
      "source": [
        "results_algorand = modelo_completo_crypto(df, \"Algorand\", print_results=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}